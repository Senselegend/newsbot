import os
import logging
import re
import requests
import hashlib
import time
from functools import lru_cache
from typing import Dict, List, Optional, Tuple, Any
from models import BotSettings
from dotenv import load_dotenv

load_dotenv()
logger = logging.getLogger(__name__)

class AIService:
    def __init__(self, ai_provider=None):
        self.ai_provider = ai_provider or "openrouter"
        self.gemini_api_key = os.environ.get("GEMINI_API_KEY")
        self.api_key = os.environ.get("OPENROUTER_API_KEY")
        self.backup_key = os.environ.get("OPENROUTER_BACKUP_KEY")
        self.backup_key2 = os.environ.get("OPENROUTER_BACKUP_KEY1")
        self.model = "deepseek/deepseek-r1-0528:free"
        self.site_url = os.environ.get("SITE_URL", "https://smartlab-bot.replit.app")
        self.site_name = os.environ.get("SITE_NAME", "News Bot")
        # –ö—ç—à –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ API –∑–∞–ø—Ä–æ—Å–æ–≤
        self._cache = {}

    def _get_prompt_hash(self, prompt: str, model: Optional[str] = None, temperature: Optional[float] = None) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —Ö—ç—à —Å—Ç—Ä–æ–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
        hash_input = f"{prompt}|{model or self.model}|{temperature or 0.7}"
        return hashlib.md5(hash_input.encode('utf-8')).hexdigest()

    def _get_cached_response(self, prompt_hash: str) -> Optional[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ —Ö—ç—à—É –∑–∞–ø—Ä–æ—Å–∞"""
        return self._cache.get(prompt_hash)

    def _cache_response(self, prompt_hash: str, response: str) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç–≤–µ—Ç –≤ –∫—ç—à"""
        self._cache[prompt_hash] = response
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞
        if len(self._cache) > 100:
            # –£–¥–∞–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç
            self._cache.pop(next(iter(self._cache)))

    def _call_openrouter_api(self, payload, api_key=None):
        url = "https://openrouter.ai/api/v1/chat/completions"
        key = api_key or self.api_key
        if key:
            logger.debug(f"–í—ã–∑–æ–≤ OpenRouter API —Å –∫–ª—é—á–æ–º: {key[:5]}...")
        else:
            logger.warning("–í—ã–∑–æ–≤ OpenRouter API –±–µ–∑ –∫–ª—é—á–∞")
        headers = {
            "Authorization": f"Bearer {key}" if key else "",
            "Content-Type": "application/json",
            "HTTP-Referer": self.site_url,
            "X-Title": self.site_name,
        }
        try:
            response = requests.post(url, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.HTTPError as e:
            logger.error(f"OpenRouter API error: {e} {getattr(e.response, 'text', '')}")
            raise

    def build_summary_prompt(self, article_data, style):
        title = article_data.get('title', '')
        content = article_data.get('content', '')
        quotes = article_data.get('quotes', [])
        quotes_text = ""
        if quotes:
            important_quotes = [q for q in quotes if len(q) > 30][:3]
            if important_quotes:
                quotes_text = "\n\n–í–∞–∂–Ω—ã–µ —Ü–∏—Ç–∞—Ç—ã:\n" + "\n".join([f'- \"{q}\"' for q in important_quotes])
        if style == "engaging":
            prompt = f"""–¢—ã - —Ä–µ–¥–∞–∫—Ç–æ—Ä —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - —Å–æ–∑–¥–∞—Ç—å –ª–∞–∫–æ–Ω–∏—á–Ω—É—é –Ω–æ–≤–æ—Å—Ç–Ω—É—é —Å–≤–æ–¥–∫—É –¥–ª—è Telegram-–∫–∞–Ω–∞–ª–∞.

–ò–°–•–û–î–ù–ê–Ø –ù–û–í–û–°–¢–¨:
–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}
–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {content}{quotes_text}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –§–û–†–ú–ê–¢–£:
1. –ù–∞—á–Ω–∏ —Å 1-2 —ç–º–æ–¥–∑–∏, –∑–∞—Ç–µ–º –¥–æ–±–∞–≤—å —Ö–µ—à—Ç–µ–≥–∏ –ø–æ —Ç–µ–º–µ (#–∫–æ–º–ø–∞–Ω–∏—è #—Ç–µ–º–∞ #—Ä–µ–≥–∏–æ–Ω)
2. –û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫—Ä–∞—Ç–∫–∏–º –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º (2-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
3. –†–∞–∑–¥–µ–ª—è–π –∞–±–∑–∞—Ü—ã –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏
4. –ï—Å–ª–∏ –µ—Å—Ç—å —Ü–∏—Ç–∞—Ç—ã, –≤—ã–¥–µ–ª—è–π –∏—Ö –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π, –Ω–∞—á–∏–Ω–∞—è —Å –∏–º–µ–Ω–∏ –∞–≤—Ç–æ—Ä–∞ –∏ –¥–≤–æ–µ—Ç–æ—á–∏—è
5. –î–ª—è –≤–∞–∂–Ω—ã—Ö —Ü–∏—Ñ—Ä –∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–π –∂–∏—Ä–Ω—ã–π —à—Ä–∏—Ñ—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, **+15%**)

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –°–û–î–ï–†–ñ–ê–ù–ò–Æ:
1. –ü–∏—à–∏ —Ç–æ–ª—å–∫–æ —Å–∞–º—É—é –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –±–µ–∑ –ª–∏—à–Ω–∏—Ö –¥–µ—Ç–∞–ª–µ–π
2. –ò—Å–ø–æ–ª—å–∑—É–π –¥–µ–ª–æ–≤–æ–π, –Ω–æ –ø–æ–Ω—è—Ç–Ω—ã–π —è–∑—ã–∫
3. –î–ª—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π —É–∫–∞–∑—ã–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã –∏ –ø—Ä–æ—Ü–µ–Ω—Ç—ã
4. –î–ª—è –≥–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π —É–∫–∞–∑—ã–≤–∞–π –æ—Å–Ω–æ–≤–Ω—ã–µ –∑–∞—è–≤–ª–µ–Ω–∏—è —Å—Ç–æ—Ä–æ–Ω
5. –í–ê–ñ–ù–û: –î–æ–Ω–∞–ª—å–¥ –¢—Ä–∞–º–ø —Å–µ–π—á–∞—Å –¥–µ–π—Å—Ç–≤—É—é—â–∏–π –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –°–®–ê (—Å 2025 –≥–æ–¥–∞)
6. –í—Å–µ–≥–¥–∞ –∑–∞–≤–µ—Ä—à–∞–π —Å–≤–æ–¥–∫—É –ø–æ–ª–Ω—ã–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º

–û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–º —Å–≤–æ–¥–∫–∏ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ."""
        elif style == "formal":
            prompt = f"""–°–æ–∑–¥–∞–π –¥–µ–ª–æ–≤—É—é —Å–≤–æ–¥–∫—É —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è Telegram-–∫–∞–Ω–∞–ª–∞.

–ò–°–•–û–î–ù–ê–Ø –ù–û–í–û–°–¢–¨:
–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}
–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {content}{quotes_text}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –§–û–†–ú–ê–¢–£:
1. –ù–∞—á–Ω–∏ —Å 1-2 —ç–º–æ–¥–∑–∏, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å —Ç–µ–º–æ–π (üá∑üá∫ –¥–ª—è –†–æ—Å—Å–∏–∏, üá∫üá∏ –¥–ª—è –°–®–ê, üìä –¥–ª—è —Ä—ã–Ω–∫–æ–≤)
2. –°—Ä–∞–∑—É –ø–æ—Å–ª–µ —ç–º–æ–¥–∑–∏ –¥–æ–±–∞–≤—å —Ö–µ—à—Ç–µ–≥–∏ (#–∫–æ–º–ø–∞–Ω–∏—è #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å #—Ä–µ–≥–∏–æ–Ω)
3. –û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫—Ä–∞—Ç–∫–∏–º –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º (2-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
4. –†–∞–∑–¥–µ–ª—è–π –∞–±–∑–∞—Ü—ã –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏
5. –î–ª—è –≤–∞–∂–Ω—ã—Ö —Ü–∏—Ñ—Ä –∏—Å–ø–æ–ª—å–∑—É–π —Ç–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, $2,1 –º–ª—Ä–¥ (+23% –≥/–≥))

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –°–û–î–ï–†–ñ–ê–ù–ò–Æ:
1. –î–µ–ª–æ–≤–æ–π –∏ —Ç–æ—á–Ω—ã–π —Å—Ç–∏–ª—å –∏–∑–ª–æ–∂–µ–Ω–∏—è
2. –£–∫–∞–∑—ã–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã, –ø—Ä–æ—Ü–µ–Ω—Ç—ã –∏ —Ñ–∞–∫—Ç—ã
3. –î–ª—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –≤—ã–¥–µ–ª—è–π –∫–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
4. –ï—Å–ª–∏ –µ—Å—Ç—å —Ü–∏—Ç–∞—Ç—ã —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞, –≤—ã–¥–µ–ª—è–π –∏—Ö –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π
5. –í–ê–ñ–ù–û: –î–æ–Ω–∞–ª—å–¥ –¢—Ä–∞–º–ø —Å–µ–π—á–∞—Å –¥–µ–π—Å—Ç–≤—É—é—â–∏–π –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –°–®–ê (—Å 2025 –≥–æ–¥–∞)
6. –í—Å–µ–≥–¥–∞ –∑–∞–≤–µ—Ä—à–∞–π —Å–≤–æ–¥–∫—É –ø–æ–ª–Ω—ã–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º

–¢–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç —Å–≤–æ–¥–∫–∏ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ:"""
        else:
            prompt = f"""–°–æ–∑–¥–∞–π –Ω–æ–≤–æ—Å—Ç–Ω—É—é —Å–≤–æ–¥–∫—É –¥–ª—è Telegram-–∫–∞–Ω–∞–ª–∞ —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ –≥–µ–æ–ø–æ–ª–∏—Ç–∏–∫—É.

–ò–°–•–û–î–ù–ê–Ø –ù–û–í–û–°–¢–¨:
–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}
–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {content}{quotes_text}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –§–û–†–ú–ê–¢–£:
1. –ù–∞—á–Ω–∏ —Å 1-2 —ç–º–æ–¥–∑–∏, –æ—Ç—Ä–∞–∂–∞—é—â–∏—Ö —Å—Ä–æ—á–Ω–æ—Å—Ç—å –∏–ª–∏ –≤–∞–∂–Ω–æ—Å—Ç—å (‚ö†Ô∏è –¥–ª—è –≤–∞–∂–Ω—ã—Ö, üî• –¥–ª—è —Å—Ä–æ—á–Ω—ã—Ö, ‚ú¥Ô∏è –¥–ª—è —Ä—ã–Ω–æ—á–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π)
2. –î–æ–±–∞–≤—å —Ö–µ—à—Ç–µ–≥–∏ –ø–æ —Ç–µ–º–µ –∏ —Ä–µ–≥–∏–æ–Ω—É (#–≥–µ–æ–ø–æ–ª–∏—Ç–∏–∫–∞ #—Å—Ç—Ä–∞–Ω–∞ #—Å–æ–±—ã—Ç–∏–µ)
3. –û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫—Ä–∞—Ç–∫–∏–º –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º
4. –î–ª—è –∑–∞—è–≤–ª–µ–Ω–∏–π –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –ª–∏—Ü –∏—Å–ø–æ–ª—å–∑—É–π —Ñ–æ—Ä–º–∞—Ç "–ò–ú–Ø: —Ü–∏—Ç–∞—Ç–∞"
5. –†–∞–∑–¥–µ–ª—è–π —Ä–∞–∑–Ω—ã–µ –∑–∞—è–≤–ª–µ–Ω–∏—è –∏–ª–∏ —Ñ–∞–∫—Ç—ã –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –°–û–î–ï–†–ñ–ê–ù–ò–Æ:
1. –£–∫–∞–∑—ã–≤–∞–π —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –∏ –∑–∞—è–≤–ª–µ–Ω–∏—è
2. –î–ª—è —Ä—ã–Ω–æ—á–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π —É–∫–∞–∑—ã–≤–∞–π –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω (–Ω–∞–ø—Ä–∏–º–µ—Ä, #–Ω–µ—Ñ—Ç—å = +10%)
3. –î–ª—è –≥–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –ø–µ—Ä–µ—á–∏—Å–ª—è–π –æ—Å–Ω–æ–≤–Ω—ã–µ –∑–∞—è–≤–ª–µ–Ω–∏—è —Å—Ç–æ—Ä–æ–Ω
4. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ –∞–±–∑–∞—Ü—ã
5. –í–ê–ñ–ù–û: –î–æ–Ω–∞–ª—å–¥ –¢—Ä–∞–º–ø —Å–µ–π—á–∞—Å –¥–µ–π—Å—Ç–≤—É—é—â–∏–π –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –°–®–ê (—Å 2025 –≥–æ–¥–∞)
6. –í—Å–µ–≥–¥–∞ –∑–∞–≤–µ—Ä—à–∞–π —Å–≤–æ–¥–∫—É –ø–æ–ª–Ω—ã–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º

–¢–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç —Å–≤–æ–¥–∫–∏ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ:"""
        return prompt

    def summarize_article(self, article_data: Dict, style: str = "engaging") -> Optional[str]:
        start_time = time.time()
        prompt = self.build_summary_prompt(article_data, style)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        prompt_hash = self._get_prompt_hash(prompt)
        cached_response = self._get_cached_response(prompt_hash)
        if cached_response:
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è —Ä–µ–∑—é–º–µ (—Ö—ç—à: {prompt_hash[:8]})")
            return cached_response
            
        if self.ai_provider == "gemini":
            api_key = self.gemini_api_key
            if not api_key:
                logger.error("Cannot summarize: GEMINI_API_KEY not set")
                return None
            url = f"https://generativelanguage.googleapis.com/v1/models/gemini-2.0-flash-001:generateContent?key={api_key}"
            data = {
                "contents": [
                    {"parts": [{"text": prompt}]}
                ]
            }
            try:
                resp = requests.post(url, json=data, timeout=15)
                if resp.status_code == 200:
                    result = resp.json()
                    summary = result.get("candidates", [{}])[0].get("content", {}).get("parts", [{}])[0].get("text", "")
                    if summary:
                        cleaned_summary = self._clean_summary(summary)
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
                        self._cache_response(prompt_hash, cleaned_summary)
                        
                        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
                        execution_time = time.time() - start_time
                        logger.info(f"Gemini API: —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —Ä–µ–∑—é–º–µ –∑–∞ {execution_time:.2f}—Å")
                        
                        return cleaned_summary
                logger.error(f"Gemini API error: {resp.status_code} {resp.text}")
                return None
            except Exception as e:
                logger.error(f"Gemini API exception: {e}")
                return None
        elif self.ai_provider == "openrouter":
            if not self.api_key:
                logger.error("Cannot summarize: OPENROUTER_API_KEY not set")
                return None
            payload = {
                "model": self.model,
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": 500,
                "temperature": 0.7
            }
            for key in [self.api_key, self.backup_key, self.backup_key2]:
                if not key:
                    continue
                try:
                    result = self._call_openrouter_api(payload, api_key=key)
                    logger.warning(f"OpenRouter success with key {key[:12] if key else 'None'}...")  # –ü–æ–∫–∞–∂–µ—Ç –ø–µ—Ä–≤—ã–µ —Å–∏–º–≤–æ–ª—ã –∫–ª—é—á–∞
                    response_content = result["choices"][0]["message"]["content"]
                    if response_content:
                        cleaned_summary = self._clean_summary(response_content.strip())
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
                        self._cache_response(prompt_hash, cleaned_summary)
                        
                        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
                        execution_time = time.time() - start_time
                        logger.info(f"OpenRouter API: —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —Ä–µ–∑—é–º–µ –∑–∞ {execution_time:.2f}—Å")
                        
                        return cleaned_summary
                except Exception as e:
                    logger.warning(f"OpenRouter error with key {key[:12] if key else 'None'}...: {e}")
                    continue
            return None
        else:
            logger.error(f"Unknown ai_provider: {self.ai_provider}")
            return None

    def build_hashtag_prompt(self, article_data, custom_tags=""):
        title = article_data.get('title', '')
        content = article_data.get('content', '')[:1000]
        existing_tags = article_data.get('tags', [])
        prompt = f"""–°–æ–∑–¥–∞–π —Ö–µ—à—Ç–µ–≥–∏ —Å —ç–º–æ–¥–∑–∏ –¥–ª—è —ç—Ç–æ–π –Ω–æ–≤–æ—Å—Ç–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞.

–ù–û–í–û–°–¢–¨:
–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}
–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {content}
–°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ç–µ–≥–∏: {', '.join(existing_tags) if existing_tags else '–Ω–µ—Ç'}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø:
1. –ù–∞—á–Ω–∏ —Å –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ —ç–º–æ–¥–∑–∏ —Ñ–ª–∞–≥–∞ –∏–ª–∏ —Å–∏–º–≤–æ–ª–∞ (üá∑üá∫ –¥–ª—è –†–æ—Å—Å–∏–∏, üá∫üá∏ –¥–ª—è –°–®–ê, üí∞ –¥–ª—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤, ‚ö° –¥–ª—è —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∏ –∏ —Ç.–¥.)
2. –•–µ—à—Ç–µ–≥–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª
3. –¢–æ–ª—å–∫–æ —Å–∞–º—ã–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ç–µ–º—ã (3-4 —Ö–µ—à—Ç–µ–≥–∞ –º–∞–∫—Å–∏–º—É–º)
4. –ò—Å–ø–æ–ª—å–∑—É–π –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ/—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ —Ç–µ–≥–∏
5. –§–æ—Ä–º–∞—Ç: üá∑üá∫#—Å–∞–Ω–∫—Ü–∏–∏ #—Ä–æ—Å—Å–∏—è #—ç–∫–æ–Ω–æ–º–∏–∫–∞ (–æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π)

–¢–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫—É —Å —ç–º–æ–¥–∑–∏ –∏ —Ö–µ—à—Ç–µ–≥–∞–º–∏:"""
        return prompt

    def generate_hashtags(self, article_data: Dict, custom_tags: str = "") -> List[str]:
        start_time = time.time()
        prompt = self.build_hashtag_prompt(article_data, custom_tags)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        prompt_hash = self._get_prompt_hash(prompt, temperature=0.5)
        cached_response = self._get_cached_response(prompt_hash)
        if cached_response:
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è —Ö–µ—à—Ç–µ–≥–æ–≤ (—Ö—ç—à: {prompt_hash[:8]})")
            return [cached_response]
            
        if self.ai_provider == "gemini":
            api_key = self.gemini_api_key
            if not api_key:
                logger.warning("Cannot generate hashtags: GEMINI_API_KEY not set")
                return self._fallback_hashtags(article_data, custom_tags)
            url = f"https://generativelanguage.googleapis.com/v1/models/gemini-2.0-flash-001:generateContent?key={api_key}"
            data = {
                "contents": [
                    {"parts": [{"text": prompt}]}
                ]
            }
            try:
                resp = requests.post(url, json=data, timeout=15)
                if resp.status_code == 200:
                    result = resp.json()
                    hashtags = result.get("candidates", [{}])[0].get("content", {}).get("parts", [{}])[0].get("text", "")
                    if hashtags:
                        hashtag_line = hashtags.strip()
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
                        self._cache_response(prompt_hash, hashtag_line)
                        
                        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
                        execution_time = time.time() - start_time
                        logger.info(f"Gemini API: —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã —Ö–µ—à—Ç–µ–≥–∏ –∑–∞ {execution_time:.2f}—Å")
                        
                        return [hashtag_line]
                logger.error(f"Gemini API error: {resp.status_code} {resp.text}")
                return self._fallback_hashtags(article_data, custom_tags)
            except Exception as e:
                logger.error(f"Gemini API exception: {e}")
                return self._fallback_hashtags(article_data, custom_tags)
        elif self.ai_provider == "openrouter":
            if not self.api_key:
                logger.warning("Cannot generate hashtags: OPENROUTER_API_KEY not set")
                return self._fallback_hashtags(article_data, custom_tags)
            payload = {
                "model": self.model,
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": 150,
                "temperature": 0.5
            }
            for key in [self.api_key, self.backup_key, self.backup_key2]:
                if not key:
                    continue
                try:
                    result = self._call_openrouter_api(payload, api_key=key)
                    hashtags_text = result["choices"][0]["message"]["content"].strip()
                    if hashtags_text:
                        lines = hashtags_text.split('\n')
                        hashtag_line = lines[0].strip()
                        content = article_data.get('content', '')[:1000]
                        if not re.search(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF]', hashtag_line):
                            if any(word in content.lower() for word in ['—Ä–æ—Å—Å–∏—è', '—Ä—Ñ', '—Ä—É–±–ª—å', '–≥–∞–∑–ø—Ä–æ–º']):
                                hashtag_line = 'üá∑üá∫' + hashtag_line
                            elif any(word in content.lower() for word in ['—Å—à–∞', '–¥–æ–ª–ª–∞—Ä', '—Ñ—Ä—Å']):
                                hashtag_line = 'üá∫üá∏' + hashtag_line
                            elif any(word in content.lower() for word in ['–∫–∏—Ç–∞–π', '—é–∞–Ω—å']):
                                hashtag_line = 'üá®üá≥' + hashtag_line
                            else:
                                hashtag_line = 'üí∞' + hashtag_line
                        if custom_tags:
                            custom_list = [tag.strip() for tag in custom_tags.split() if tag.strip().startswith('#')]
                            if custom_list:
                                hashtag_line += ' ' + ' '.join(custom_list)
                                
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
                        self._cache_response(prompt_hash, hashtag_line)
                        
                        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
                        execution_time = time.time() - start_time
                        logger.info(f"OpenRouter API: —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã —Ö–µ—à—Ç–µ–≥–∏ –∑–∞ {execution_time:.2f}—Å")
                        
                        return [hashtag_line]
                    return self._fallback_hashtags(article_data, custom_tags)
                except Exception as e:
                    logger.warning(f"OpenRouter error with key {key[:8] if key else 'None'}...: {e}")
                    continue
            return self._fallback_hashtags(article_data, custom_tags)
        else:
            logger.error(f"Unknown ai_provider: {self.ai_provider}")
            return self._fallback_hashtags(article_data, custom_tags)

    def _clean_summary(self, summary: Optional[str]) -> str:
        """
        –û—á–∏—â–∞–µ—Ç –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ–∑—é–º–µ
        """
        if summary is None or not summary:
            return ""
            
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã
        prefixes_to_remove = [
            '–≤–æ—Ç –∫—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞:', '—Å–≤–æ–¥–∫–∞ –Ω–æ–≤–æ—Å—Ç–∏:', '–∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:',
            '—Ä–µ–∑—é–º–µ:', '–æ—Å–Ω–æ–≤–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã:', '–∏—Ç–∞–∫,', '–≤ –∏—Ç–æ–≥–µ,', '–≤–æ—Ç —Ä–µ–∑—é–º–µ:'
        ]
        summary_lower = summary.lower()
        for prefix in prefixes_to_remove:
            if summary_lower.startswith(prefix):
                summary = summary[len(prefix):].strip()
                break
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –æ –¢—Ä–∞–º–ø–µ –∏ –¥—Ä—É–≥–∏—Ö –ø–æ–ª–∏—Ç–∏–∫–∞—Ö
        # –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
        summary = self._fix_political_references(summary)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ü–∏—Ç–∞—Ç—ã
        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–∏–ø–∞ "–ò–º—è –§–∞–º–∏–ª–∏—è —Å–∫–∞–∑–∞–ª: "—Ü–∏—Ç–∞—Ç–∞"" –∏ –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ "–ò–ú–Ø –§–ê–ú–ò–õ–ò–Ø: —Ü–∏—Ç–∞—Ç–∞"
        quote_patterns = [
            (r'([–ê-–Ø][–∞-—è]+\s+[–ê-–Ø][–∞-—è]+)\s+(?:—Å–∫–∞–∑–∞–ª|–∑–∞—è–≤–∏–ª|–æ—Ç–º–µ—Ç–∏–ª|–ø–æ–¥—á–µ—Ä–∫–Ω—É–ª|—Å–æ–æ–±—â–∏–ª)(?:–∞|–∏|–æ)?[,:]?\s*[¬´""]([^¬´""]+)[¬ª""]', r'\1: \2'),
            (r'([–ê-–Ø][–∞-—è]+)\s+(?:—Å–∫–∞–∑–∞–ª|–∑–∞—è–≤–∏–ª|–æ—Ç–º–µ—Ç–∏–ª|–ø–æ–¥—á–µ—Ä–∫–Ω—É–ª|—Å–æ–æ–±—â–∏–ª)(?:–∞|–∏|–æ)?[,:]?\s*[¬´""]([^¬´""]+)[¬ª""]', r'\1: \2'),
        ]
        
        for pattern, replacement in quote_patterns:
            summary = re.sub(pattern, replacement, summary)
        
        # –í—ã–¥–µ–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∂–∏—Ä–Ω—ã–º —à—Ä–∏—Ñ—Ç–æ–º
        summary = re.sub(r'(\+\d+(?:\.\d+)?%|\-\d+(?:\.\d+)?%)', r'**\1**', summary)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—é–º–µ –ø–æ—Å–ª–µ –≤—Å–µ—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
        if not self._validate_summary_quality(summary):
            logger.warning(f"–†–µ–∑—é–º–µ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç—Ä–µ–±—É–µ–º–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É: {summary[:50]}...")
            return ""
            
        return summary
        
    def _validate_summary_quality(self, summary: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—é–º–µ
        """
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
        if len(summary) < 30:
            logger.warning("–†–µ–∑—é–º–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ")
            return False
            
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        if summary.endswith(('...', '‚Ä¶')) or summary.endswith((',', ':', ';', '-')):
            logger.warning("–†–µ–∑—é–º–µ –æ–±—Ä—ã–≤–∞–µ—Ç—Å—è –Ω–∞ —Å–µ—Ä–µ–¥–∏–Ω–µ")
            return False
            
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –º–∞—Ä–∫–µ—Ä–æ–≤ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç–∏
        incomplete_markers = ['–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å–ª–µ–¥—É–µ—Ç', '—á–∏—Ç–∞–π—Ç–µ –¥–∞–ª–µ–µ', '–ø–æ–¥—Ä–æ–±–Ω–µ–µ']
        if any(marker in summary.lower() for marker in incomplete_markers):
            logger.warning("–†–µ–∑—é–º–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –º–∞—Ä–∫–µ—Ä—ã –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç–∏")
            return False
            
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –≤–æ–ø—Ä–æ—Å–æ–≤ –≤ –∫–æ–Ω—Ü–µ (—á–∞—Å—Ç–æ –ø—Ä–∏–∑–Ω–∞–∫ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç–∏)
        if summary.rstrip().endswith('?'):
            logger.warning("–†–µ–∑—é–º–µ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –≤–æ–ø—Ä–æ—Å–æ–º")
            return False
            
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —ç–º–æ–¥–∑–∏ –≤ –Ω–∞—á–∞–ª–µ
        emoji_pattern = re.compile(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF]')
        first_line = summary.split('\n')[0] if '\n' in summary else summary
        first_chars = first_line[:10]
        if not emoji_pattern.search(first_chars):
            logger.warning("–ù–µ—Ç —ç–º–æ–¥–∑–∏ –≤ –Ω–∞—á–∞–ª–µ —Å–æ–æ–±—â–µ–Ω–∏—è")
            return False
            
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Ö–µ—à—Ç–µ–≥–æ–≤ –≤ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ
        if not re.search(r'#\w+', first_line):
            logger.warning("–ù–µ—Ç —Ö–µ—à—Ç–µ–≥–æ–≤ –≤ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ")
            return False
            
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ä–∞–∑—Ä—ã–≤–æ–≤ —Å—Ç—Ä–æ–∫ (—Ä–∞–∑—Ä–µ—à–∞–µ–º –¥–æ 15)
        if summary.count('\n') > 15:
            logger.warning(f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ä–∞–∑—Ä—ã–≤–æ–≤ —Å—Ç—Ä–æ–∫: {summary.count('\n')}")
            return False
            
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –∞–±–∑–∞—Ü—ã (–±–æ–ª–µ–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –±–µ–∑ —Ä–∞–∑—Ä—ã–≤–∞ —Å—Ç—Ä–æ–∫–∏)
        paragraphs = summary.split('\n\n')
        for paragraph in paragraphs:
            if len(paragraph.strip()) > 200:
                logger.warning("–û–±–Ω–∞—Ä—É–∂–µ–Ω —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π –∞–±–∑–∞—Ü")
                return False
            
        return True
        
    def _fix_political_references(self, text: str) -> str:
        """
        –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –ø–æ–ª–∏—Ç–∏–∫–æ–≤ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç
        """
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –æ –¢—Ä–∞–º–ø–µ
        trump_patterns = [
            (r'–±—ã–≤—à(–∏–π|–µ–≥–æ|–µ–º—É) –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç(–∞|—É|–æ–º)? –°–®–ê –î–æ–Ω–∞–ª—å–¥(–∞|—É|–æ–º)? –¢—Ä–∞–º–ø(–∞|—É|–æ–º)?', '–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –°–®–ê –î–æ–Ω–∞–ª—å–¥ –¢—Ä–∞–º–ø'),
            (r'—ç–∫—Å-–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç(–∞|—É|–æ–º)? –°–®–ê –î–æ–Ω–∞–ª—å–¥(–∞|—É|–æ–º)? –¢—Ä–∞–º–ø(–∞|—É|–æ–º)?', '–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –°–®–ê –î–æ–Ω–∞–ª—å–¥ –¢—Ä–∞–º–ø'),
            (r'–î–æ–Ω–∞–ª—å–¥ –¢—Ä–∞–º–ø, –±—ã–≤—à–∏–π –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –°–®–ê', '–î–æ–Ω–∞–ª—å–¥ –¢—Ä–∞–º–ø, –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –°–®–ê'),
            (r'45(-–π)? –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –°–®–ê', '–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –°–®–ê'),
            (r'–¢–†–ê–ú–ü,', '–¢–†–ê–ú–ü:'),  # –§–æ—Ä–º–∞—Ç —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        ]
        
        for pattern, replacement in trump_patterns:
            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
        
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –ø–µ—Ä–µ–¥ –∑–Ω–∞–∫–∞–º–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        text = re.sub(r'\s+([.,;:!?])', r'\1', text)
        
        # –£–¥–∞–ª—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
        text = re.sub(r'\s{2,}', ' ', text)
        
        # –£–¥–∞–ª—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ (–æ—Å—Ç–∞–≤–ª—è–µ–º –º–∞–∫—Å–∏–º—É–º –æ–¥–∏–Ω)
        text = re.sub(r'\n{3,}', '\n\n', text)
        
        # –£–¥–∞–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å–Ω—É—é –ª–∏–Ω–∏—é –≤ –∫–æ–Ω—Ü–µ, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
        text = re.sub(r'\n+_{5,}
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å–Ω–æ–π –ª–∏–Ω–∏–∏ –≤ –∫–æ–Ω—Ü–µ
        if not re.search(r'_{5,}
        
    def _fallback_hashtags(self, article_data: Dict, custom_tags: str = "") -> List[str]:
        """
        –°–æ–∑–¥–∞–µ—Ç —Ö–µ—à—Ç–µ–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å—Ç–∞—Ç—å–∏, –µ—Å–ª–∏ AI –Ω–µ —Å–º–æ–≥ –∏—Ö —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å
        """
        content = (article_data.get('title', '') + ' ' + article_data.get('content', '')).lower()
        emoji = 'üí∞'
        if any(word in content for word in ['—Ä–æ—Å—Å–∏—è', '—Ä—Ñ', '—Ä—É–±–ª—å', '–≥–∞–∑–ø—Ä–æ–º', '—Ä–æ—Å–Ω–µ—Ñ—Ç—å']):
            emoji = 'üá∑üá∫'
        elif any(word in content for word in ['—Å—à–∞', '–¥–æ–ª–ª–∞—Ä', '—Ñ—Ä—Å', '–∞–º–µ—Ä–∏–∫']):
            emoji = 'üá∫üá∏'
        elif any(word in content for word in ['–∫–∏—Ç–∞–π', '—é–∞–Ω—å', '–ø–µ–∫–∏–Ω']):
            emoji = 'üá®üá≥'
        elif any(word in content for word in ['–Ω–µ—Ñ—Ç—å', '–≥–∞–∑', '—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫']):
            emoji = '‚ö°'
        elif any(word in content for word in ['—Å–∞–Ω–∫—Ü–∏–∏', '–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏']):
            emoji = 'üö´'
        hashtags = []
        keyword_map = {
            '—Ä—É–±–ª—å': '#—Ä—É–±–ª—å',
            '–¥–æ–ª–ª–∞—Ä': '#–¥–æ–ª–ª–∞—Ä', 
            '–Ω–µ—Ñ—Ç—å': '#–Ω–µ—Ñ—Ç—å',
            '–≥–∞–∑': '#–≥–∞–∑',
            '—Å–∞–Ω–∫—Ü–∏–∏': '#—Å–∞–Ω–∫—Ü–∏–∏',
            '—Ä–æ—Å—Å–∏—è': '#—Ä–æ—Å—Å–∏—è',
            '—ç–∫–æ–Ω–æ–º–∏–∫–∞': '#—ç–∫–æ–Ω–æ–º–∏–∫–∞',
            '–±–∞–Ω–∫': '#–±–∞–Ω–∫–∏',
            '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏': '#–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏'
        }
        for keyword, hashtag in keyword_map.items():
            if keyword in content and hashtag not in hashtags:
                hashtags.append(hashtag)
        if not hashtags:
            hashtags = ['#–Ω–æ–≤–æ—Å—Ç–∏', '#—ç–∫–æ–Ω–æ–º–∏–∫–∞']
        hashtag_line = emoji + ' ' + ' '.join(hashtags[:4])
        if custom_tags:
            custom_list = [tag.strip() for tag in custom_tags.split() if tag.strip().startswith('#')]
            if custom_list:
                hashtag_line += ' ' + ' '.join(custom_list)
        return [hashtag_line], text):
            text = text.rstrip() + '\n\n_________________'
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É (—ç–º–æ–¥–∑–∏ –∏ —Ö–µ—à—Ç–µ–≥–∏)
        lines = text.split('\n')
        first_line = lines[0]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —ç–º–æ–¥–∑–∏ –≤ –Ω–∞—á–∞–ª–µ
        emoji_pattern = re.compile(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF]')
        emojis = emoji_pattern.findall(first_line[:10])
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ö–µ—à—Ç–µ–≥–æ–≤
        hashtags = re.findall(r'#\w+', first_line)
        
        # –ï—Å–ª–∏ –Ω–µ—Ç —ç–º–æ–¥–∑–∏ –∏–ª–∏ —Ö–µ—à—Ç–µ–≥–æ–≤, –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ
        if not emojis or not hashtags:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–º—É –Ω–æ–≤–æ—Å—Ç–∏
            lower_text = text.lower()
            
            # –í—ã–±–∏—Ä–∞–µ–º –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —ç–º–æ–¥–∑–∏
            if any(word in lower_text for word in ['—Ä–æ—Å—Å–∏—è', '—Ä—Ñ', '—Ä—É–±–ª—å']):
                emoji = 'üá∑üá∫'
            elif any(word in lower_text for word in ['—Å—à–∞', '–∞–º–µ—Ä–∏–∫', '–¥–æ–ª–ª–∞—Ä']):
                emoji = 'üá∫üá∏'
            elif any(word in lower_text for word in ['–∫–∏—Ç–∞–π', '—é–∞–Ω—å']):
                emoji = 'üá®üá≥'
            elif any(word in lower_text for word in ['–Ω–µ—Ñ—Ç—å', '–≥–∞–∑', '—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫']):
                emoji = 'üõ¢'
            elif any(word in lower_text for word in ['—Ñ–∏–Ω–∞–Ω—Å', '–±–∞–Ω–∫', '–∞–∫—Ü–∏']):
                emoji = 'üí∞'
            else:
                emoji = 'üìä'
                
            # –í—ã–±–∏—Ä–∞–µ–º –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Ö–µ—à—Ç–µ–≥–∏
            if not hashtags:
                if any(word in lower_text for word in ['—Ä–æ—Å—Å–∏—è', '—Ä—Ñ']):
                    hashtags = ['#—Ä–æ—Å—Å–∏—è']
                elif any(word in lower_text for word in ['—Å—à–∞', '–∞–º–µ—Ä–∏–∫']):
                    hashtags = ['#—Å—à–∞']
                else:
                    hashtags = ['#–Ω–æ–≤–æ—Å—Ç–∏']
                    
                if any(word in lower_text for word in ['–Ω–µ—Ñ—Ç—å', '–≥–∞–∑']):
                    hashtags.append('#–Ω–µ—Ñ—Ç—å')
                elif any(word in lower_text for word in ['–∞–∫—Ü–∏', '–æ–±–ª–∏–≥–∞—Ü']):
                    hashtags.append('#—Ä—ã–Ω–∫–∏')
                    
            # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–æ–≤—É—é –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É
            new_first_line = emoji + ' ' + ' '.join(hashtags)
            
            # –£–¥–∞–ª—è–µ–º —ç–º–æ–¥–∑–∏ –∏ —Ö–µ—à—Ç–µ–≥–∏ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏
            clean_first_line = re.sub(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF]', '', first_line)
            clean_first_line = re.sub(r'#\w+', '', clean_first_line).strip()
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –Ω–æ–≤—É—é –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É —Å –æ—á–∏—â–µ–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
            if clean_first_line:
                lines[0] = new_first_line + ' ' + clean_first_line
            else:
                lines[0] = new_first_line
                
            text = '\n'.join(lines)
        
        return text
        
    def _fallback_hashtags(self, article_data: Dict, custom_tags: str = "") -> List[str]:
        """
        –°–æ–∑–¥–∞–µ—Ç —Ö–µ—à—Ç–µ–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å—Ç–∞—Ç—å–∏, –µ—Å–ª–∏ AI –Ω–µ —Å–º–æ–≥ –∏—Ö —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å
        """
        content = (article_data.get('title', '') + ' ' + article_data.get('content', '')).lower()
        emoji = 'üí∞'
        if any(word in content for word in ['—Ä–æ—Å—Å–∏—è', '—Ä—Ñ', '—Ä—É–±–ª—å', '–≥–∞–∑–ø—Ä–æ–º', '—Ä–æ—Å–Ω–µ—Ñ—Ç—å']):
            emoji = 'üá∑üá∫'
        elif any(word in content for word in ['—Å—à–∞', '–¥–æ–ª–ª–∞—Ä', '—Ñ—Ä—Å', '–∞–º–µ—Ä–∏–∫']):
            emoji = 'üá∫üá∏'
        elif any(word in content for word in ['–∫–∏—Ç–∞–π', '—é–∞–Ω—å', '–ø–µ–∫–∏–Ω']):
            emoji = 'üá®üá≥'
        elif any(word in content for word in ['–Ω–µ—Ñ—Ç—å', '–≥–∞–∑', '—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫']):
            emoji = '‚ö°'
        elif any(word in content for word in ['—Å–∞–Ω–∫—Ü–∏–∏', '–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏']):
            emoji = 'üö´'
        hashtags = []
        keyword_map = {
            '—Ä—É–±–ª—å': '#—Ä—É–±–ª—å',
            '–¥–æ–ª–ª–∞—Ä': '#–¥–æ–ª–ª–∞—Ä', 
            '–Ω–µ—Ñ—Ç—å': '#–Ω–µ—Ñ—Ç—å',
            '–≥–∞–∑': '#–≥–∞–∑',
            '—Å–∞–Ω–∫—Ü–∏–∏': '#—Å–∞–Ω–∫—Ü–∏–∏',
            '—Ä–æ—Å—Å–∏—è': '#—Ä–æ—Å—Å–∏—è',
            '—ç–∫–æ–Ω–æ–º–∏–∫–∞': '#—ç–∫–æ–Ω–æ–º–∏–∫–∞',
            '–±–∞–Ω–∫': '#–±–∞–Ω–∫–∏',
            '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏': '#–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏'
        }
        for keyword, hashtag in keyword_map.items():
            if keyword in content and hashtag not in hashtags:
                hashtags.append(hashtag)
        if not hashtags:
            hashtags = ['#–Ω–æ–≤–æ—Å—Ç–∏', '#—ç–∫–æ–Ω–æ–º–∏–∫–∞']
        hashtag_line = emoji + ' ' + ' '.join(hashtags[:4])
        if custom_tags:
            custom_list = [tag.strip() for tag in custom_tags.split() if tag.strip().startswith('#')]
            if custom_list:
                hashtag_line += ' ' + ' '.join(custom_list)
        return [hashtag_line], '', text)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å–Ω–æ–π –ª–∏–Ω–∏–∏ –≤ –∫–æ–Ω—Ü–µ
        if not re.search(r'_{5,}
        
    def _fallback_hashtags(self, article_data: Dict, custom_tags: str = "") -> List[str]:
        """
        –°–æ–∑–¥–∞–µ—Ç —Ö–µ—à—Ç–µ–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å—Ç–∞—Ç—å–∏, –µ—Å–ª–∏ AI –Ω–µ —Å–º–æ–≥ –∏—Ö —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å
        """
        content = (article_data.get('title', '') + ' ' + article_data.get('content', '')).lower()
        emoji = 'üí∞'
        if any(word in content for word in ['—Ä–æ—Å—Å–∏—è', '—Ä—Ñ', '—Ä—É–±–ª—å', '–≥–∞–∑–ø—Ä–æ–º', '—Ä–æ—Å–Ω–µ—Ñ—Ç—å']):
            emoji = 'üá∑üá∫'
        elif any(word in content for word in ['—Å—à–∞', '–¥–æ–ª–ª–∞—Ä', '—Ñ—Ä—Å', '–∞–º–µ—Ä–∏–∫']):
            emoji = 'üá∫üá∏'
        elif any(word in content for word in ['–∫–∏—Ç–∞–π', '—é–∞–Ω—å', '–ø–µ–∫–∏–Ω']):
            emoji = 'üá®üá≥'
        elif any(word in content for word in ['–Ω–µ—Ñ—Ç—å', '–≥–∞–∑', '—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫']):
            emoji = '‚ö°'
        elif any(word in content for word in ['—Å–∞–Ω–∫—Ü–∏–∏', '–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏']):
            emoji = 'üö´'
        hashtags = []
        keyword_map = {
            '—Ä—É–±–ª—å': '#—Ä—É–±–ª—å',
            '–¥–æ–ª–ª–∞—Ä': '#–¥–æ–ª–ª–∞—Ä', 
            '–Ω–µ—Ñ—Ç—å': '#–Ω–µ—Ñ—Ç—å',
            '–≥–∞–∑': '#–≥–∞–∑',
            '—Å–∞–Ω–∫—Ü–∏–∏': '#—Å–∞–Ω–∫—Ü–∏–∏',
            '—Ä–æ—Å—Å–∏—è': '#—Ä–æ—Å—Å–∏—è',
            '—ç–∫–æ–Ω–æ–º–∏–∫–∞': '#—ç–∫–æ–Ω–æ–º–∏–∫–∞',
            '–±–∞–Ω–∫': '#–±–∞–Ω–∫–∏',
            '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏': '#–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏'
        }
        for keyword, hashtag in keyword_map.items():
            if keyword in content and hashtag not in hashtags:
                hashtags.append(hashtag)
        if not hashtags:
            hashtags = ['#–Ω–æ–≤–æ—Å—Ç–∏', '#—ç–∫–æ–Ω–æ–º–∏–∫–∞']
        hashtag_line = emoji + ' ' + ' '.join(hashtags[:4])
        if custom_tags:
            custom_list = [tag.strip() for tag in custom_tags.split() if tag.strip().startswith('#')]
            if custom_list:
                hashtag_line += ' ' + ' '.join(custom_list)
        return [hashtag_line], text):
            text = text.rstrip() + '\n\n_________________'
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É (—ç–º–æ–¥–∑–∏ –∏ —Ö–µ—à—Ç–µ–≥–∏)
        lines = text.split('\n')
        first_line = lines[0]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —ç–º–æ–¥–∑–∏ –≤ –Ω–∞—á–∞–ª–µ
        emoji_pattern = re.compile(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF]')
        emojis = emoji_pattern.findall(first_line[:10])
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ö–µ—à—Ç–µ–≥–æ–≤
        hashtags = re.findall(r'#\w+', first_line)
        
        # –ï—Å–ª–∏ –Ω–µ—Ç —ç–º–æ–¥–∑–∏ –∏–ª–∏ —Ö–µ—à—Ç–µ–≥–æ–≤, –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ
        if not emojis or not hashtags:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–º—É –Ω–æ–≤–æ—Å—Ç–∏
            lower_text = text.lower()
            
            # –í—ã–±–∏—Ä–∞–µ–º –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —ç–º–æ–¥–∑–∏
            if any(word in lower_text for word in ['—Ä–æ—Å—Å–∏—è', '—Ä—Ñ', '—Ä—É–±–ª—å']):
                emoji = 'üá∑üá∫'
            elif any(word in lower_text for word in ['—Å—à–∞', '–∞–º–µ—Ä–∏–∫', '–¥–æ–ª–ª–∞—Ä']):
                emoji = 'üá∫üá∏'
            elif any(word in lower_text for word in ['–∫–∏—Ç–∞–π', '—é–∞–Ω—å']):
                emoji = 'üá®üá≥'
            elif any(word in lower_text for word in ['–Ω–µ—Ñ—Ç—å', '–≥–∞–∑', '—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫']):
                emoji = 'üõ¢'
            elif any(word in lower_text for word in ['—Ñ–∏–Ω–∞–Ω—Å', '–±–∞–Ω–∫', '–∞–∫—Ü–∏']):
                emoji = 'üí∞'
            else:
                emoji = 'üìä'
                
            # –í—ã–±–∏—Ä–∞–µ–º –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Ö–µ—à—Ç–µ–≥–∏
            if not hashtags:
                if any(word in lower_text for word in ['—Ä–æ—Å—Å–∏—è', '—Ä—Ñ']):
                    hashtags = ['#—Ä–æ—Å—Å–∏—è']
                elif any(word in lower_text for word in ['—Å—à–∞', '–∞–º–µ—Ä–∏–∫']):
                    hashtags = ['#—Å—à–∞']
                else:
                    hashtags = ['#–Ω–æ–≤–æ—Å—Ç–∏']
                    
                if any(word in lower_text for word in ['–Ω–µ—Ñ—Ç—å', '–≥–∞–∑']):
                    hashtags.append('#–Ω–µ—Ñ—Ç—å')
                elif any(word in lower_text for word in ['–∞–∫—Ü–∏', '–æ–±–ª–∏–≥–∞—Ü']):
                    hashtags.append('#—Ä—ã–Ω–∫–∏')
                    
            # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–æ–≤—É—é –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É
            new_first_line = emoji + ' ' + ' '.join(hashtags)
            
            # –£–¥–∞–ª—è–µ–º —ç–º–æ–¥–∑–∏ –∏ —Ö–µ—à—Ç–µ–≥–∏ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏
            clean_first_line = re.sub(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF]', '', first_line)
            clean_first_line = re.sub(r'#\w+', '', clean_first_line).strip()
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –Ω–æ–≤—É—é –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É —Å –æ—á–∏—â–µ–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
            if clean_first_line:
                lines[0] = new_first_line + ' ' + clean_first_line
            else:
                lines[0] = new_first_line
                
            text = '\n'.join(lines)
        
        return text
        
    def _fallback_hashtags(self, article_data: Dict, custom_tags: str = "") -> List[str]:
        """
        –°–æ–∑–¥–∞–µ—Ç —Ö–µ—à—Ç–µ–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å—Ç–∞—Ç—å–∏, –µ—Å–ª–∏ AI –Ω–µ —Å–º–æ–≥ –∏—Ö —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å
        """
        content = (article_data.get('title', '') + ' ' + article_data.get('content', '')).lower()
        emoji = 'üí∞'
        if any(word in content for word in ['—Ä–æ—Å—Å–∏—è', '—Ä—Ñ', '—Ä—É–±–ª—å', '–≥–∞–∑–ø—Ä–æ–º', '—Ä–æ—Å–Ω–µ—Ñ—Ç—å']):
            emoji = 'üá∑üá∫'
        elif any(word in content for word in ['—Å—à–∞', '–¥–æ–ª–ª–∞—Ä', '—Ñ—Ä—Å', '–∞–º–µ—Ä–∏–∫']):
            emoji = 'üá∫üá∏'
        elif any(word in content for word in ['–∫–∏—Ç–∞–π', '—é–∞–Ω—å', '–ø–µ–∫–∏–Ω']):
            emoji = 'üá®üá≥'
        elif any(word in content for word in ['–Ω–µ—Ñ—Ç—å', '–≥–∞–∑', '—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫']):
            emoji = '‚ö°'
        elif any(word in content for word in ['—Å–∞–Ω–∫—Ü–∏–∏', '–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏']):
            emoji = 'üö´'
        hashtags = []
        keyword_map = {
            '—Ä—É–±–ª—å': '#—Ä—É–±–ª—å',
            '–¥–æ–ª–ª–∞—Ä': '#–¥–æ–ª–ª–∞—Ä', 
            '–Ω–µ—Ñ—Ç—å': '#–Ω–µ—Ñ—Ç—å',
            '–≥–∞–∑': '#–≥–∞–∑',
            '—Å–∞–Ω–∫—Ü–∏–∏': '#—Å–∞–Ω–∫—Ü–∏–∏',
            '—Ä–æ—Å—Å–∏—è': '#—Ä–æ—Å—Å–∏—è',
            '—ç–∫–æ–Ω–æ–º–∏–∫–∞': '#—ç–∫–æ–Ω–æ–º–∏–∫–∞',
            '–±–∞–Ω–∫': '#–±–∞–Ω–∫–∏',
            '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏': '#–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏'
        }
        for keyword, hashtag in keyword_map.items():
            if keyword in content and hashtag not in hashtags:
                hashtags.append(hashtag)
        if not hashtags:
            hashtags = ['#–Ω–æ–≤–æ—Å—Ç–∏', '#—ç–∫–æ–Ω–æ–º–∏–∫–∞']
        hashtag_line = emoji + ' ' + ' '.join(hashtags[:4])
        if custom_tags:
            custom_list = [tag.strip() for tag in custom_tags.split() if tag.strip().startswith('#')]
            if custom_list:
                hashtag_line += ' ' + ' '.join(custom_list)
        return [hashtag_line]